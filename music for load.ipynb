{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/librosa/core/audio.py:37: UserWarning: Could not import scikits.samplerate. Falling back to scipy.signal\n",
      "  warnings.warn('Could not import scikits.samplerate. '\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import cross_validation\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import dill\n",
    "# Build a dictionary of file names\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('datasets/music_train_labels.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    fileGenreDict = {'data/train/'+rows[0]:rows[1] for rows in reader}\n",
    "# Just as an example....To write the file back out .....    \n",
    "#    with open('coors_new.csv', mode='w') as outfile:\n",
    "#        writer = csv.writer(outfile)\n",
    "# Generate Label Encoding\n",
    "genreList = []\n",
    "genreDistinct = []\n",
    "for key, value in fileGenreDict.iteritems():\n",
    "    if value not in genreList:\n",
    "        genreDistinct.append(value)\n",
    "    genreList.append(value)    \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(genreDistinct)\n",
    "transformedGenres = le.transform(genreList)\n",
    "invTransfedGenres = le.inverse_transform(transformedGenres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to create features\n",
    "def create_features():\n",
    "    x = []\n",
    "    mono, fs = librosa.load('datasets/processed/mp3File.mp3', sr = 44100)\n",
    "    frameLength = int(len(mono)/20)\n",
    "    zcr = librosa.feature.zero_crossing_rate(mono, frame_length=frameLength, hop_length=frameLength-512, center=True)\n",
    "    rms = librosa.feature.rmse(mono, S=None, n_fft=frameLength, hop_length=frameLength-512)\n",
    "#    print 'Number of ZCR columns:%s\\nNumber of RMS columns:%s' % (len(zcr[0]), len(rms[0])) \n",
    "    \n",
    "    rms_mean = np.mean(rms[0])\n",
    "    rms_std  = np.std(rms[0])\n",
    "    rms_skew = scipy.stats.skew(rms[0], axis=0, bias=True)\n",
    "#    rms_kurt = scipy.stats.kurtosis(rms[0], axis=0, fisher=True, bias=True)\n",
    " \n",
    "    zcr_mean = np.mean(zcr[0])\n",
    "    zcr_std  = np.std(zcr[0])\n",
    "    zcr_skew = scipy.stats.skew(zcr[0], axis=0, bias=True)\n",
    "#    zcr_kurt = scipy.stats.kurtosis(zcr[0], axis=0, fisher=True, bias=True)\n",
    "    \n",
    "#    x = np.append(zcr[0], rms[0])    \n",
    "    x = [rms_mean, rms_std, rms_skew, zcr_mean, zcr_std, zcr_skew]\n",
    "    \n",
    "    return x\n",
    "# Create features, one file at a time and build the dataset for classification\n",
    "t = tarfile.open(\"datasets/music_train.tar\", 'r')\n",
    "y = []\n",
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in t.getnames():\n",
    "    t.extract(f, 'datasets/processed/')\n",
    "    os.rename('datasets/processed/'+f, 'datasets/processed/mp3File.mp3')\n",
    "    genre = fileGenreDict[f]\n",
    "    y.append(le.transform(genre))\n",
    "#    print y, genre\n",
    "# --- Call the function to create the features using mp3File.mp3 ......    \n",
    "    X.append(create_features())\n",
    "t.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167\n",
      "1167\n"
     ]
    }
   ],
   "source": [
    "print len(X)\n",
    "print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\\\n",
    "                    X, y, test_size=0.2, random_state=42) \n",
    "q1Model = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\n",
    "q1Model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the model generated above to the Grader data : music_feature_extraction_test.tar\n",
    "# First Create features, one file at a time and build the test dataset for classification\n",
    "t = tarfile.open(\"datasets/music_feature_extraction_test.tar\", 'r')\n",
    "yt = []\n",
    "Xt = []\n",
    "for f in t.getnames():\n",
    "    t.extract(f, 'datasets/processed/')\n",
    "    os.rename('datasets/processed/'+f, 'datasets/processed/mp3File.mp3')\n",
    "    yt.append(f)\n",
    "# --- Call the function to create the features using mp3File.mp3 ......    \n",
    "    Xt.append(create_features())\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fe_test_0001.mp3', 'fe_test_0002.mp3', 'fe_test_0003.mp3', 'fe_test_0004.mp3', 'fe_test_0005.mp3', 'fe_test_0006.mp3', 'fe_test_0007.mp3', 'fe_test_0008.mp3', 'fe_test_0009.mp3', 'fe_test_0010.mp3', 'fe_test_0011.mp3', 'fe_test_0012.mp3', 'fe_test_0013.mp3', 'fe_test_0014.mp3', 'fe_test_0015.mp3', 'fe_test_0016.mp3', 'fe_test_0017.mp3', 'fe_test_0018.mp3', 'fe_test_0019.mp3', 'fe_test_0020.mp3', 'fe_test_0021.mp3', 'fe_test_0022.mp3', 'fe_test_0023.mp3', 'fe_test_0024.mp3', 'fe_test_0025.mp3', 'fe_test_0026.mp3', 'fe_test_0027.mp3', 'fe_test_0028.mp3', 'fe_test_0029.mp3', 'fe_test_0030.mp3', 'fe_test_0031.mp3', 'fe_test_0032.mp3', 'fe_test_0033.mp3', 'fe_test_0034.mp3', 'fe_test_0035.mp3', 'fe_test_0036.mp3', 'fe_test_0037.mp3', 'fe_test_0038.mp3', 'fe_test_0039.mp3', 'fe_test_0040.mp3', 'fe_test_0041.mp3', 'fe_test_0042.mp3', 'fe_test_0043.mp3', 'fe_test_0044.mp3', 'fe_test_0045.mp3', 'fe_test_0046.mp3', 'fe_test_0047.mp3', 'fe_test_0048.mp3', 'fe_test_0049.mp3', 'fe_test_0050.mp3', 'fe_test_0051.mp3', 'fe_test_0052.mp3', 'fe_test_0053.mp3', 'fe_test_0054.mp3', 'fe_test_0055.mp3', 'fe_test_0056.mp3', 'fe_test_0057.mp3', 'fe_test_0058.mp3', 'fe_test_0059.mp3', 'fe_test_0060.mp3', 'fe_test_0061.mp3', 'fe_test_0062.mp3', 'fe_test_0063.mp3', 'fe_test_0064.mp3', 'fe_test_0065.mp3', 'fe_test_0066.mp3', 'fe_test_0067.mp3', 'fe_test_0068.mp3', 'fe_test_0069.mp3', 'fe_test_0070.mp3', 'fe_test_0071.mp3', 'fe_test_0072.mp3', 'fe_test_0073.mp3', 'fe_test_0074.mp3', 'fe_test_0075.mp3', 'fe_test_0076.mp3', 'fe_test_0077.mp3', 'fe_test_0078.mp3', 'fe_test_0079.mp3', 'fe_test_0080.mp3', 'fe_test_0081.mp3', 'fe_test_0082.mp3', 'fe_test_0083.mp3', 'fe_test_0084.mp3', 'fe_test_0085.mp3', 'fe_test_0086.mp3', 'fe_test_0087.mp3', 'fe_test_0088.mp3', 'fe_test_0089.mp3', 'fe_test_0090.mp3', 'fe_test_0091.mp3', 'fe_test_0092.mp3', 'fe_test_0093.mp3', 'fe_test_0094.mp3', 'fe_test_0095.mp3', 'fe_test_0096.mp3', 'fe_test_0097.mp3', 'fe_test_0098.mp3', 'fe_test_0099.mp3', 'fe_test_0100.mp3', 'fe_test_0101.mp3', 'fe_test_0102.mp3', 'fe_test_0103.mp3', 'fe_test_0104.mp3', 'fe_test_0105.mp3', 'fe_test_0106.mp3', 'fe_test_0107.mp3', 'fe_test_0108.mp3', 'fe_test_0109.mp3', 'fe_test_0110.mp3', 'fe_test_0111.mp3', 'fe_test_0112.mp3', 'fe_test_0113.mp3', 'fe_test_0114.mp3', 'fe_test_0115.mp3', 'fe_test_0116.mp3', 'fe_test_0117.mp3', 'fe_test_0118.mp3', 'fe_test_0119.mp3', 'fe_test_0120.mp3', 'fe_test_0121.mp3', 'fe_test_0122.mp3', 'fe_test_0123.mp3', 'fe_test_0124.mp3', 'fe_test_0125.mp3', 'fe_test_0126.mp3', 'fe_test_0127.mp3', 'fe_test_0128.mp3', 'fe_test_0129.mp3', 'fe_test_0130.mp3', 'fe_test_0131.mp3', 'fe_test_0132.mp3', 'fe_test_0133.mp3', 'fe_test_0134.mp3', 'fe_test_0135.mp3', 'fe_test_0136.mp3', 'fe_test_0137.mp3', 'fe_test_0138.mp3', 'fe_test_0139.mp3', 'fe_test_0140.mp3', 'fe_test_0141.mp3', 'fe_test_0142.mp3', 'fe_test_0143.mp3', 'fe_test_0144.mp3', 'fe_test_0145.mp3']\n",
      "fe_test_0145.mp3\n"
     ]
    }
   ],
   "source": [
    "yt2 = [i[-16:] for i in yt]\n",
    "print yt2\n",
    "print yt2[144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "outPredict = le.inverse_transform(q1Model.predict(Xt))\n",
    "# Q1 Output\n",
    "#for i in xrange(len(outPredict)):\n",
    "#    print yt2[i]+':'+ outPredict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "{'fe_test_0041.mp3': 'rock', 'fe_test_0023.mp3': 'rock', 'fe_test_0079.mp3': 'jazz', 'fe_test_0144.mp3': 'raphiphop', 'fe_test_0133.mp3': 'raphiphop', 'fe_test_0019.mp3': 'jazz', 'fe_test_0052.mp3': 'jazz', 'fe_test_0059.mp3': 'raphiphop', 'fe_test_0017.mp3': 'jazz', 'fe_test_0103.mp3': 'rock', 'fe_test_0111.mp3': 'raphiphop', 'fe_test_0024.mp3': 'jazz', 'fe_test_0012.mp3': 'rock', 'fe_test_0075.mp3': 'rock', 'fe_test_0115.mp3': 'jazz', 'fe_test_0062.mp3': 'jazz', 'fe_test_0137.mp3': 'rock', 'fe_test_0055.mp3': 'jazz', 'fe_test_0093.mp3': 'raphiphop', 'fe_test_0049.mp3': 'jazz', 'fe_test_0016.mp3': 'rock', 'fe_test_0026.mp3': 'rock', 'fe_test_0002.mp3': 'rock', 'fe_test_0065.mp3': 'raphiphop', 'fe_test_0129.mp3': 'jazz', 'fe_test_0045.mp3': 'rock', 'fe_test_0057.mp3': 'rock', 'fe_test_0127.mp3': 'jazz', 'fe_test_0015.mp3': 'raphiphop', 'fe_test_0124.mp3': 'rock', 'fe_test_0114.mp3': 'rock', 'fe_test_0145.mp3': 'raphiphop', 'fe_test_0120.mp3': 'raphiphop', 'fe_test_0089.mp3': 'raphiphop', 'fe_test_0108.mp3': 'rock', 'fe_test_0142.mp3': 'jazz', 'fe_test_0047.mp3': 'raphiphop', 'fe_test_0048.mp3': 'jazz', 'fe_test_0009.mp3': 'rock', 'fe_test_0116.mp3': 'rock', 'fe_test_0077.mp3': 'jazz', 'fe_test_0001.mp3': 'jazz', 'fe_test_0073.mp3': 'rock', 'fe_test_0040.mp3': 'rock', 'fe_test_0058.mp3': 'jazz', 'fe_test_0109.mp3': 'jazz', 'fe_test_0125.mp3': 'rock', 'fe_test_0084.mp3': 'rock', 'fe_test_0032.mp3': 'jazz', 'fe_test_0078.mp3': 'rock', 'fe_test_0036.mp3': 'rock', 'fe_test_0135.mp3': 'rock', 'fe_test_0018.mp3': 'raphiphop', 'fe_test_0056.mp3': 'rock', 'fe_test_0098.mp3': 'rock', 'fe_test_0139.mp3': 'jazz', 'fe_test_0083.mp3': 'rock', 'fe_test_0087.mp3': 'rock', 'fe_test_0064.mp3': 'rock', 'fe_test_0074.mp3': 'rock', 'fe_test_0143.mp3': 'jazz', 'fe_test_0022.mp3': 'rock', 'fe_test_0021.mp3': 'jazz', 'fe_test_0037.mp3': 'jazz', 'fe_test_0104.mp3': 'jazz', 'fe_test_0025.mp3': 'rock', 'fe_test_0134.mp3': 'jazz', 'fe_test_0140.mp3': 'rock', 'fe_test_0131.mp3': 'raphiphop', 'fe_test_0007.mp3': 'rock', 'fe_test_0130.mp3': 'jazz', 'fe_test_0043.mp3': 'jazz', 'fe_test_0092.mp3': 'jazz', 'fe_test_0082.mp3': 'rock', 'fe_test_0100.mp3': 'jazz', 'fe_test_0035.mp3': 'rock', 'fe_test_0086.mp3': 'jazz', 'fe_test_0118.mp3': 'jazz', 'fe_test_0067.mp3': 'jazz', 'fe_test_0076.mp3': 'jazz', 'fe_test_0107.mp3': 'jazz', 'fe_test_0095.mp3': 'rock', 'fe_test_0096.mp3': 'rock', 'fe_test_0091.mp3': 'rock', 'fe_test_0112.mp3': 'rock', 'fe_test_0020.mp3': 'rock', 'fe_test_0014.mp3': 'rock', 'fe_test_0068.mp3': 'rock', 'fe_test_0117.mp3': 'jazz', 'fe_test_0039.mp3': 'jazz', 'fe_test_0010.mp3': 'raphiphop', 'fe_test_0141.mp3': 'jazz', 'fe_test_0044.mp3': 'jazz', 'fe_test_0072.mp3': 'raphiphop', 'fe_test_0050.mp3': 'rock', 'fe_test_0099.mp3': 'jazz', 'fe_test_0097.mp3': 'jazz', 'fe_test_0090.mp3': 'raphiphop', 'fe_test_0113.mp3': 'rock', 'fe_test_0105.mp3': 'jazz', 'fe_test_0088.mp3': 'rock', 'fe_test_0029.mp3': 'jazz', 'fe_test_0006.mp3': 'rock', 'fe_test_0008.mp3': 'rock', 'fe_test_0110.mp3': 'rock', 'fe_test_0081.mp3': 'raphiphop', 'fe_test_0011.mp3': 'jazz', 'fe_test_0122.mp3': 'rock', 'fe_test_0066.mp3': 'rock', 'fe_test_0005.mp3': 'rock', 'fe_test_0061.mp3': 'raphiphop', 'fe_test_0051.mp3': 'jazz', 'fe_test_0042.mp3': 'jazz', 'fe_test_0126.mp3': 'jazz', 'fe_test_0013.mp3': 'rock', 'fe_test_0132.mp3': 'rock', 'fe_test_0119.mp3': 'rock', 'fe_test_0136.mp3': 'rock', 'fe_test_0094.mp3': 'rock', 'fe_test_0031.mp3': 'rock', 'fe_test_0106.mp3': 'rock', 'fe_test_0121.mp3': 'rock', 'fe_test_0034.mp3': 'jazz', 'fe_test_0004.mp3': 'rock', 'fe_test_0070.mp3': 'raphiphop', 'fe_test_0046.mp3': 'rock', 'fe_test_0054.mp3': 'rock', 'fe_test_0080.mp3': 'jazz', 'fe_test_0030.mp3': 'rock', 'fe_test_0123.mp3': 'rock', 'fe_test_0085.mp3': 'raphiphop', 'fe_test_0028.mp3': 'rock', 'fe_test_0038.mp3': 'jazz', 'fe_test_0003.mp3': 'jazz', 'fe_test_0060.mp3': 'rock', 'fe_test_0101.mp3': 'raphiphop', 'fe_test_0033.mp3': 'jazz', 'fe_test_0102.mp3': 'rock', 'fe_test_0027.mp3': 'rock', 'fe_test_0069.mp3': 'rock', 'fe_test_0071.mp3': 'jazz', 'fe_test_0138.mp3': 'rock', 'fe_test_0063.mp3': 'raphiphop', 'fe_test_0053.mp3': 'raphiphop', 'fe_test_0128.mp3': 'rock'}\n"
     ]
    }
   ],
   "source": [
    "q1_ans = dict((yt2[i], outPredict[i]) for i in range(0,145))\n",
    "print len(q1_ans)\n",
    "print q1_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "############\n",
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features2():\n",
    "    x = []\n",
    "    mono, fs = librosa.load('datasets/processed/mp3File.mp3', sr = 44100)\n",
    "    frameLength = int(len(mono)/20)\n",
    "    zcr = librosa.feature.zero_crossing_rate(mono, frame_length=2048, hop_length=512, center=True)\n",
    "    rms = librosa.feature.rmse(mono, S=None, n_fft=2048, hop_length=512)\n",
    "    mfcc= librosa.feature.mfcc(mono, sr=44100, S=None, n_mfcc=24)\n",
    "    # And the first-order differences (delta features)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "#    print 'Number of ZCR columns:%s\\nNumber of RMS columns:%s' % (len(zcr[0]), len(rms[0])) \n",
    "#    zcr:  (1, 867)\n",
    "#    rms:  (1, 867)\n",
    "#    mfcc:  (20, 867)\n",
    "    \n",
    "    rms_mean = np.mean(rms[0])\n",
    "    rms_std  = np.std(rms[0])\n",
    "    rms_skew = scipy.stats.skew(rms[0], axis=0, bias=True)\n",
    "#    rms_kurt = scipy.stats.kurtosis(rms[0], axis=0, fisher=True, bias=True)\n",
    "            \n",
    "    zcr_mean = np.mean(zcr[0])\n",
    "    zcr_std  = np.std(zcr[0])\n",
    "    zcr_skew = scipy.stats.skew(zcr[0], axis=0, bias=True)\n",
    "#    zcr_kurt = scipy.stats.kurtosis(zcr[0], axis=0, fisher=True, bias=True)\n",
    "  \n",
    "    mfcc_mean = []\n",
    "    mfcc_std  = []\n",
    "    mfcc_skew = []\n",
    "    mfcc_kurt = []\n",
    "    for i in range(len(mfcc[:, 0])):\n",
    "        mfcc_mean.append(np.mean(mfcc[i]))\n",
    "        mfcc_std.append(np.std(mfcc[i]))\n",
    "        mfcc_skew.append(scipy.stats.skew(mfcc[i], axis=0, bias=True))\n",
    "        mfcc_kurt.append(scipy.stats.kurtosis(mfcc[i], axis=0, fisher=True, bias=True))\n",
    "    mfcc_delta_mean = []\n",
    "    mfcc_delta_std  = []\n",
    "    mfcc_delta_skew = []\n",
    "    mfcc_delta_kurt = []\n",
    "    for i in range(len(mfcc_delta[:, 0])):\n",
    "        mfcc_delta_mean.append(np.mean(mfcc_delta[i]))\n",
    "        mfcc_delta_std.append(np.std(mfcc_delta[i]))\n",
    "        mfcc_delta_skew.append(scipy.stats.skew(mfcc_delta[i], axis=0, bias=True))\n",
    "        mfcc_delta_kurt.append(scipy.stats.kurtosis(mfcc_delta[i], axis=0, fisher=True, bias=True))\n",
    "        \n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "#    y_harmonic, y_percussive = librosa.effects.hpss(mono)\n",
    "    # Beat track on the percussive signal\n",
    "#    tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=44100)\n",
    "    \n",
    "        \n",
    "    x = [[rms_mean, rms_std, rms_skew, zcr_mean, zcr_std, zcr_skew],\\\n",
    "          mfcc_mean, mfcc_std, mfcc_skew, mfcc_kurt,\\\n",
    "          mfcc_delta_mean, mfcc_delta_std, mfcc_delta_skew, mfcc_delta_kurt]\n",
    "    \n",
    "    X = [item for sublist in x for item in sublist]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create features, one file at a time and build the dataset for classification\n",
    "t = tarfile.open(\"datasets/music_train.tar\", 'r')\n",
    "y = []\n",
    "X = []\n",
    "for f in t.getnames():\n",
    "    t.extract(f, 'datasets/processed/')\n",
    "    os.rename('datasets/processed/'+f, 'datasets/processed/mp3File.mp3')\n",
    "    genre = fileGenreDict[f]\n",
    "    y.append(le.transform(genre))\n",
    "#    print y, genre\n",
    "# --- Call the function to create the features using mp3File.mp3 ......    \n",
    "    X.append(create_features2())\n",
    "t.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75026795284030012"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "XScaled = scaler.transform(X)\n",
    "le.inverse_transform(y)\n",
    "# Standardize the X data\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "# Scale X before applying PCA\n",
    "X_Scaled = scaler.transform(X)\n",
    "pca = PCA(n_components=50)\n",
    "q2pca = pca.fit(X_Scaled)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\\\n",
    "                    X_Scaled, y, test_size=0.2, random_state=0) \n",
    "# Reshape the X and y vectors\n",
    "X_almost_ready = np.asarray(X_train).reshape(len(X_train),198).astype(np.float)\n",
    "y_ready = np.asarray(y_train).reshape(len(y_train),1)\n",
    "# Apply the PCA transformer\n",
    "X_ready = q2pca.transform(X_almost_ready)\n",
    "# Build the model\n",
    "q2Model = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_ready, y_ready)\n",
    "q2Model.score(X_ready, y_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70940170940170943"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the model on the holdout dataset\n",
    "##################################################################################################\n",
    "# Scale X before applying the model\n",
    "#X_test_Scaled = scaler.transform(X_test)\n",
    "X_test_Scaled = X_test\n",
    "# Reshape the X vector\n",
    "X_test_almost_ready = np.asarray(X_test_Scaled).reshape(len(X_test_Scaled),198).astype(np.float)\n",
    "# Apply the PCA transformer\n",
    "X_test_ready = q2pca.transform(X_test_almost_ready)\n",
    "# Apply the model\n",
    "y_pred = q2Model.predict(X_test_ready)\n",
    "# Convert the encoded labels back\n",
    "y_pred_decode = le.inverse_transform(y_pred)\n",
    "y_test_ready = np.asarray(y_test).reshape(len(y_test),1)\n",
    "q2Model.score(X_test_ready, y_test_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe_test_0001.mp3 jazz\n",
      "fe_test_0002.mp3 rock\n",
      "fe_test_0003.mp3 raphiphop\n",
      "fe_test_0004.mp3 rock\n",
      "fe_test_0005.mp3 rock\n",
      "fe_test_0006.mp3 rock\n",
      "fe_test_0007.mp3 rock\n",
      "fe_test_0008.mp3 rock\n",
      "fe_test_0009.mp3 rock\n",
      "fe_test_0010.mp3 raphiphop\n",
      "fe_test_0011.mp3 jazz\n",
      "fe_test_0012.mp3 rock\n",
      "fe_test_0013.mp3 rock\n",
      "fe_test_0014.mp3 rock\n",
      "fe_test_0015.mp3 rock\n",
      "fe_test_0016.mp3 rock\n",
      "fe_test_0017.mp3 raphiphop\n",
      "fe_test_0018.mp3 raphiphop\n",
      "fe_test_0019.mp3 jazz\n",
      "fe_test_0020.mp3 rock\n",
      "fe_test_0021.mp3 jazz\n",
      "fe_test_0022.mp3 rock\n",
      "fe_test_0023.mp3 rock\n",
      "fe_test_0024.mp3 jazz\n",
      "fe_test_0025.mp3 raphiphop\n",
      "fe_test_0026.mp3 folkcountry\n",
      "fe_test_0027.mp3 rock\n",
      "fe_test_0028.mp3 rock\n",
      "fe_test_0029.mp3 rock\n",
      "fe_test_0030.mp3 rock\n",
      "fe_test_0031.mp3 rock\n",
      "fe_test_0032.mp3 jazz\n",
      "fe_test_0033.mp3 raphiphop\n",
      "fe_test_0034.mp3 jazz\n",
      "fe_test_0035.mp3 rock\n",
      "fe_test_0036.mp3 rock\n",
      "fe_test_0037.mp3 jazz\n",
      "fe_test_0038.mp3 folkcountry\n",
      "fe_test_0039.mp3 jazz\n",
      "fe_test_0040.mp3 rock\n",
      "fe_test_0041.mp3 rock\n",
      "fe_test_0042.mp3 rock\n",
      "fe_test_0043.mp3 rock\n",
      "fe_test_0044.mp3 jazz\n",
      "fe_test_0045.mp3 electronic\n",
      "fe_test_0046.mp3 jazz\n",
      "fe_test_0047.mp3 raphiphop\n",
      "fe_test_0048.mp3 raphiphop\n",
      "fe_test_0049.mp3 jazz\n",
      "fe_test_0050.mp3 rock\n",
      "fe_test_0051.mp3 jazz\n",
      "fe_test_0052.mp3 jazz\n",
      "fe_test_0053.mp3 folkcountry\n",
      "fe_test_0054.mp3 jazz\n",
      "fe_test_0055.mp3 folkcountry\n",
      "fe_test_0056.mp3 rock\n",
      "fe_test_0057.mp3 jazz\n",
      "fe_test_0058.mp3 jazz\n",
      "fe_test_0059.mp3 raphiphop\n",
      "fe_test_0060.mp3 rock\n",
      "fe_test_0061.mp3 raphiphop\n",
      "fe_test_0062.mp3 folkcountry\n",
      "fe_test_0063.mp3 jazz\n",
      "fe_test_0064.mp3 rock\n",
      "fe_test_0065.mp3 raphiphop\n",
      "fe_test_0066.mp3 rock\n",
      "fe_test_0067.mp3 jazz\n",
      "fe_test_0068.mp3 rock\n",
      "fe_test_0069.mp3 raphiphop\n",
      "fe_test_0070.mp3 electronic\n",
      "fe_test_0071.mp3 rock\n",
      "fe_test_0072.mp3 raphiphop\n",
      "fe_test_0073.mp3 electronic\n",
      "fe_test_0074.mp3 folkcountry\n",
      "fe_test_0075.mp3 rock\n",
      "fe_test_0076.mp3 jazz\n",
      "fe_test_0077.mp3 folkcountry\n",
      "fe_test_0078.mp3 rock\n",
      "fe_test_0079.mp3 rock\n",
      "fe_test_0080.mp3 jazz\n",
      "fe_test_0081.mp3 raphiphop\n",
      "fe_test_0082.mp3 rock\n",
      "fe_test_0083.mp3 raphiphop\n",
      "fe_test_0084.mp3 rock\n",
      "fe_test_0085.mp3 folkcountry\n",
      "fe_test_0086.mp3 folkcountry\n",
      "fe_test_0087.mp3 rock\n",
      "fe_test_0088.mp3 rock\n",
      "fe_test_0089.mp3 raphiphop\n",
      "fe_test_0090.mp3 rock\n",
      "fe_test_0091.mp3 rock\n",
      "fe_test_0092.mp3 raphiphop\n",
      "fe_test_0093.mp3 raphiphop\n",
      "fe_test_0094.mp3 raphiphop\n",
      "fe_test_0095.mp3 rock\n",
      "fe_test_0096.mp3 rock\n",
      "fe_test_0097.mp3 jazz\n",
      "fe_test_0098.mp3 rock\n",
      "fe_test_0099.mp3 jazz\n",
      "fe_test_0100.mp3 raphiphop\n",
      "fe_test_0101.mp3 electronic\n",
      "fe_test_0102.mp3 rock\n",
      "fe_test_0103.mp3 rock\n",
      "fe_test_0104.mp3 jazz\n",
      "fe_test_0105.mp3 jazz\n",
      "fe_test_0106.mp3 rock\n",
      "fe_test_0107.mp3 jazz\n",
      "fe_test_0108.mp3 rock\n",
      "fe_test_0109.mp3 rock\n",
      "fe_test_0110.mp3 rock\n",
      "fe_test_0111.mp3 jazz\n",
      "fe_test_0112.mp3 rock\n",
      "fe_test_0113.mp3 rock\n",
      "fe_test_0114.mp3 folkcountry\n",
      "fe_test_0115.mp3 folkcountry\n",
      "fe_test_0116.mp3 rock\n",
      "fe_test_0117.mp3 jazz\n",
      "fe_test_0118.mp3 raphiphop\n",
      "fe_test_0119.mp3 rock\n",
      "fe_test_0120.mp3 electronic\n",
      "fe_test_0121.mp3 rock\n",
      "fe_test_0122.mp3 rock\n",
      "fe_test_0123.mp3 rock\n",
      "fe_test_0124.mp3 raphiphop\n",
      "fe_test_0125.mp3 rock\n",
      "fe_test_0126.mp3 jazz\n",
      "fe_test_0127.mp3 raphiphop\n",
      "fe_test_0128.mp3 rock\n",
      "fe_test_0129.mp3 folkcountry\n",
      "fe_test_0130.mp3 jazz\n",
      "fe_test_0131.mp3 jazz\n",
      "fe_test_0132.mp3 rock\n",
      "fe_test_0133.mp3 raphiphop\n",
      "fe_test_0134.mp3 folkcountry\n",
      "fe_test_0135.mp3 rock\n",
      "fe_test_0136.mp3 rock\n",
      "fe_test_0137.mp3 folkcountry\n",
      "fe_test_0138.mp3 rock\n",
      "fe_test_0139.mp3 jazz\n",
      "fe_test_0140.mp3 rock\n",
      "fe_test_0141.mp3 raphiphop\n",
      "fe_test_0142.mp3 raphiphop\n",
      "fe_test_0143.mp3 jazz\n",
      "fe_test_0144.mp3 folkcountry\n",
      "fe_test_0145.mp3 raphiphop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply the model generated above to the Grader data : music_feature_extraction_test.tar\n",
    "\n",
    "# First Create features, one file at a time and build the test dataset for classification\n",
    "t = tarfile.open(\"datasets/music_feature_extraction_test.tar\", 'r')\n",
    "yt = []\n",
    "Xt = []\n",
    "for f in t.getnames():\n",
    "    t.extract(f, 'datasets/processed/')\n",
    "    os.rename('datasets/processed/'+f, 'datasets/processed/mp3File.mp3')\n",
    "    yt.append(f)\n",
    "# --- Call the function to create the features using mp3File.mp3 ......    \n",
    "    Xt.append(create_features2())\n",
    "t.close()\n",
    "# Scale X before fitting\n",
    "Xt_Scaled = scaler.transform(Xt)\n",
    "# Reshape the X vector\n",
    "Xt_almost_ready = np.asarray(Xt_Scaled).reshape(len(Xt_Scaled),198).astype(np.float)\n",
    "# Apply the PCA transformer\n",
    "Xt_ready = q2pca.transform(Xt_almost_ready)\n",
    "# Apply the model\n",
    "yt_pred = q2Model.predict(Xt_ready)\n",
    "outPredict = le.inverse_transform(q2Model.predict(Xt_ready))\n",
    "# Q2 Output\n",
    "for i in xrange(len(outPredict)):\n",
    "    print yt[i][29:], outPredict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fe_test_0001.mp3', 'fe_test_0002.mp3', 'fe_test_0003.mp3', 'fe_test_0004.mp3', 'fe_test_0005.mp3', 'fe_test_0006.mp3', 'fe_test_0007.mp3', 'fe_test_0008.mp3', 'fe_test_0009.mp3', 'fe_test_0010.mp3', 'fe_test_0011.mp3', 'fe_test_0012.mp3', 'fe_test_0013.mp3', 'fe_test_0014.mp3', 'fe_test_0015.mp3', 'fe_test_0016.mp3', 'fe_test_0017.mp3', 'fe_test_0018.mp3', 'fe_test_0019.mp3', 'fe_test_0020.mp3', 'fe_test_0021.mp3', 'fe_test_0022.mp3', 'fe_test_0023.mp3', 'fe_test_0024.mp3', 'fe_test_0025.mp3', 'fe_test_0026.mp3', 'fe_test_0027.mp3', 'fe_test_0028.mp3', 'fe_test_0029.mp3', 'fe_test_0030.mp3', 'fe_test_0031.mp3', 'fe_test_0032.mp3', 'fe_test_0033.mp3', 'fe_test_0034.mp3', 'fe_test_0035.mp3', 'fe_test_0036.mp3', 'fe_test_0037.mp3', 'fe_test_0038.mp3', 'fe_test_0039.mp3', 'fe_test_0040.mp3', 'fe_test_0041.mp3', 'fe_test_0042.mp3', 'fe_test_0043.mp3', 'fe_test_0044.mp3', 'fe_test_0045.mp3', 'fe_test_0046.mp3', 'fe_test_0047.mp3', 'fe_test_0048.mp3', 'fe_test_0049.mp3', 'fe_test_0050.mp3', 'fe_test_0051.mp3', 'fe_test_0052.mp3', 'fe_test_0053.mp3', 'fe_test_0054.mp3', 'fe_test_0055.mp3', 'fe_test_0056.mp3', 'fe_test_0057.mp3', 'fe_test_0058.mp3', 'fe_test_0059.mp3', 'fe_test_0060.mp3', 'fe_test_0061.mp3', 'fe_test_0062.mp3', 'fe_test_0063.mp3', 'fe_test_0064.mp3', 'fe_test_0065.mp3', 'fe_test_0066.mp3', 'fe_test_0067.mp3', 'fe_test_0068.mp3', 'fe_test_0069.mp3', 'fe_test_0070.mp3', 'fe_test_0071.mp3', 'fe_test_0072.mp3', 'fe_test_0073.mp3', 'fe_test_0074.mp3', 'fe_test_0075.mp3', 'fe_test_0076.mp3', 'fe_test_0077.mp3', 'fe_test_0078.mp3', 'fe_test_0079.mp3', 'fe_test_0080.mp3', 'fe_test_0081.mp3', 'fe_test_0082.mp3', 'fe_test_0083.mp3', 'fe_test_0084.mp3', 'fe_test_0085.mp3', 'fe_test_0086.mp3', 'fe_test_0087.mp3', 'fe_test_0088.mp3', 'fe_test_0089.mp3', 'fe_test_0090.mp3', 'fe_test_0091.mp3', 'fe_test_0092.mp3', 'fe_test_0093.mp3', 'fe_test_0094.mp3', 'fe_test_0095.mp3', 'fe_test_0096.mp3', 'fe_test_0097.mp3', 'fe_test_0098.mp3', 'fe_test_0099.mp3', 'fe_test_0100.mp3', 'fe_test_0101.mp3', 'fe_test_0102.mp3', 'fe_test_0103.mp3', 'fe_test_0104.mp3', 'fe_test_0105.mp3', 'fe_test_0106.mp3', 'fe_test_0107.mp3', 'fe_test_0108.mp3', 'fe_test_0109.mp3', 'fe_test_0110.mp3', 'fe_test_0111.mp3', 'fe_test_0112.mp3', 'fe_test_0113.mp3', 'fe_test_0114.mp3', 'fe_test_0115.mp3', 'fe_test_0116.mp3', 'fe_test_0117.mp3', 'fe_test_0118.mp3', 'fe_test_0119.mp3', 'fe_test_0120.mp3', 'fe_test_0121.mp3', 'fe_test_0122.mp3', 'fe_test_0123.mp3', 'fe_test_0124.mp3', 'fe_test_0125.mp3', 'fe_test_0126.mp3', 'fe_test_0127.mp3', 'fe_test_0128.mp3', 'fe_test_0129.mp3', 'fe_test_0130.mp3', 'fe_test_0131.mp3', 'fe_test_0132.mp3', 'fe_test_0133.mp3', 'fe_test_0134.mp3', 'fe_test_0135.mp3', 'fe_test_0136.mp3', 'fe_test_0137.mp3', 'fe_test_0138.mp3', 'fe_test_0139.mp3', 'fe_test_0140.mp3', 'fe_test_0141.mp3', 'fe_test_0142.mp3', 'fe_test_0143.mp3', 'fe_test_0144.mp3', 'fe_test_0145.mp3']\n",
      "fe_test_0145.mp3\n"
     ]
    }
   ],
   "source": [
    "yt2 = [i[-16:] for i in yt]\n",
    "print yt2\n",
    "print yt2[144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "{'fe_test_0041.mp3': 'rock', 'fe_test_0023.mp3': 'rock', 'fe_test_0079.mp3': 'rock', 'fe_test_0144.mp3': 'folkcountry', 'fe_test_0133.mp3': 'raphiphop', 'fe_test_0019.mp3': 'jazz', 'fe_test_0052.mp3': 'jazz', 'fe_test_0059.mp3': 'raphiphop', 'fe_test_0017.mp3': 'raphiphop', 'fe_test_0103.mp3': 'rock', 'fe_test_0111.mp3': 'jazz', 'fe_test_0024.mp3': 'jazz', 'fe_test_0012.mp3': 'rock', 'fe_test_0075.mp3': 'rock', 'fe_test_0115.mp3': 'folkcountry', 'fe_test_0062.mp3': 'folkcountry', 'fe_test_0137.mp3': 'folkcountry', 'fe_test_0055.mp3': 'folkcountry', 'fe_test_0093.mp3': 'raphiphop', 'fe_test_0049.mp3': 'jazz', 'fe_test_0016.mp3': 'rock', 'fe_test_0026.mp3': 'folkcountry', 'fe_test_0002.mp3': 'rock', 'fe_test_0065.mp3': 'raphiphop', 'fe_test_0129.mp3': 'folkcountry', 'fe_test_0045.mp3': 'electronic', 'fe_test_0057.mp3': 'jazz', 'fe_test_0127.mp3': 'raphiphop', 'fe_test_0015.mp3': 'rock', 'fe_test_0124.mp3': 'raphiphop', 'fe_test_0114.mp3': 'folkcountry', 'fe_test_0145.mp3': 'raphiphop', 'fe_test_0120.mp3': 'electronic', 'fe_test_0089.mp3': 'raphiphop', 'fe_test_0108.mp3': 'rock', 'fe_test_0142.mp3': 'raphiphop', 'fe_test_0047.mp3': 'raphiphop', 'fe_test_0048.mp3': 'raphiphop', 'fe_test_0009.mp3': 'rock', 'fe_test_0116.mp3': 'rock', 'fe_test_0077.mp3': 'folkcountry', 'fe_test_0001.mp3': 'jazz', 'fe_test_0073.mp3': 'electronic', 'fe_test_0040.mp3': 'rock', 'fe_test_0058.mp3': 'jazz', 'fe_test_0109.mp3': 'rock', 'fe_test_0125.mp3': 'rock', 'fe_test_0084.mp3': 'rock', 'fe_test_0032.mp3': 'jazz', 'fe_test_0078.mp3': 'rock', 'fe_test_0036.mp3': 'rock', 'fe_test_0135.mp3': 'rock', 'fe_test_0018.mp3': 'raphiphop', 'fe_test_0056.mp3': 'rock', 'fe_test_0098.mp3': 'rock', 'fe_test_0139.mp3': 'jazz', 'fe_test_0083.mp3': 'raphiphop', 'fe_test_0087.mp3': 'rock', 'fe_test_0064.mp3': 'rock', 'fe_test_0074.mp3': 'folkcountry', 'fe_test_0143.mp3': 'jazz', 'fe_test_0022.mp3': 'rock', 'fe_test_0021.mp3': 'jazz', 'fe_test_0037.mp3': 'jazz', 'fe_test_0104.mp3': 'jazz', 'fe_test_0025.mp3': 'raphiphop', 'fe_test_0134.mp3': 'folkcountry', 'fe_test_0140.mp3': 'rock', 'fe_test_0131.mp3': 'jazz', 'fe_test_0007.mp3': 'rock', 'fe_test_0130.mp3': 'jazz', 'fe_test_0043.mp3': 'rock', 'fe_test_0092.mp3': 'raphiphop', 'fe_test_0082.mp3': 'rock', 'fe_test_0100.mp3': 'raphiphop', 'fe_test_0035.mp3': 'rock', 'fe_test_0086.mp3': 'folkcountry', 'fe_test_0118.mp3': 'raphiphop', 'fe_test_0067.mp3': 'jazz', 'fe_test_0076.mp3': 'jazz', 'fe_test_0107.mp3': 'jazz', 'fe_test_0095.mp3': 'rock', 'fe_test_0096.mp3': 'rock', 'fe_test_0091.mp3': 'rock', 'fe_test_0112.mp3': 'rock', 'fe_test_0020.mp3': 'rock', 'fe_test_0014.mp3': 'rock', 'fe_test_0068.mp3': 'rock', 'fe_test_0117.mp3': 'jazz', 'fe_test_0039.mp3': 'jazz', 'fe_test_0010.mp3': 'raphiphop', 'fe_test_0141.mp3': 'raphiphop', 'fe_test_0044.mp3': 'jazz', 'fe_test_0072.mp3': 'raphiphop', 'fe_test_0050.mp3': 'rock', 'fe_test_0099.mp3': 'jazz', 'fe_test_0097.mp3': 'jazz', 'fe_test_0090.mp3': 'rock', 'fe_test_0113.mp3': 'rock', 'fe_test_0105.mp3': 'jazz', 'fe_test_0088.mp3': 'rock', 'fe_test_0029.mp3': 'rock', 'fe_test_0006.mp3': 'rock', 'fe_test_0008.mp3': 'rock', 'fe_test_0110.mp3': 'rock', 'fe_test_0081.mp3': 'raphiphop', 'fe_test_0011.mp3': 'jazz', 'fe_test_0122.mp3': 'rock', 'fe_test_0066.mp3': 'rock', 'fe_test_0005.mp3': 'rock', 'fe_test_0061.mp3': 'raphiphop', 'fe_test_0051.mp3': 'jazz', 'fe_test_0042.mp3': 'rock', 'fe_test_0126.mp3': 'jazz', 'fe_test_0013.mp3': 'rock', 'fe_test_0132.mp3': 'rock', 'fe_test_0119.mp3': 'rock', 'fe_test_0136.mp3': 'rock', 'fe_test_0094.mp3': 'raphiphop', 'fe_test_0031.mp3': 'rock', 'fe_test_0106.mp3': 'rock', 'fe_test_0121.mp3': 'rock', 'fe_test_0034.mp3': 'jazz', 'fe_test_0004.mp3': 'rock', 'fe_test_0070.mp3': 'electronic', 'fe_test_0046.mp3': 'jazz', 'fe_test_0054.mp3': 'jazz', 'fe_test_0080.mp3': 'jazz', 'fe_test_0030.mp3': 'rock', 'fe_test_0123.mp3': 'rock', 'fe_test_0085.mp3': 'folkcountry', 'fe_test_0028.mp3': 'rock', 'fe_test_0038.mp3': 'folkcountry', 'fe_test_0003.mp3': 'raphiphop', 'fe_test_0060.mp3': 'rock', 'fe_test_0101.mp3': 'electronic', 'fe_test_0033.mp3': 'raphiphop', 'fe_test_0102.mp3': 'rock', 'fe_test_0027.mp3': 'rock', 'fe_test_0069.mp3': 'raphiphop', 'fe_test_0071.mp3': 'rock', 'fe_test_0138.mp3': 'rock', 'fe_test_0063.mp3': 'jazz', 'fe_test_0053.mp3': 'folkcountry', 'fe_test_0128.mp3': 'rock'}\n"
     ]
    }
   ],
   "source": [
    "q2_ans = dict((yt2[i], outPredict[i]) for i in range(0,145))\n",
    "print len(q2_ans)\n",
    "print q2_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import cross_validation\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import dill\n",
    "df_train_list = []\n",
    "with open('datasets/df_train_anon.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    df_train_list = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df_train_list[0])\n",
    "yq3 = []\n",
    "Xq3 = []\n",
    "temp_list = []\n",
    "for rows in df_train_list:\n",
    "    temp_list.append(rows)       \n",
    "    yq3.append(temp_list[0][-1])\n",
    "    Xq3.append(temp_list[0][0:-1])\n",
    "    temp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167\n",
      "1167\n",
      "['jazz', 'jazz', 'electronic', 'jazz', 'electronic']\n"
     ]
    }
   ],
   "source": [
    "print len(yq3)\n",
    "print len(Xq3)\n",
    "print yq3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize the X data\n",
    "scaler = preprocessing.StandardScaler().fit(Xq3)\n",
    "#print Xq3[0]\n",
    "#print scaler\n",
    "# Generate Label Encoding\n",
    "le = preprocessing.LabelEncoder().fit(yq3)\n",
    "# le.classes_\n",
    "# invTransf_y = le.inverse_transform(y)\n",
    "# Scale X before applying PCA\n",
    "Xq3Scaled = scaler.transform(Xq3)\n",
    "# Build PCA transformer\n",
    "pca = PCA(n_components=80)\n",
    "q3pca = pca.fit(Xq3Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Xfit_tran = pca.fit_transform(X_train)\n",
    "X_train=Xq3\n",
    "y_train=yq3\n",
    "# Scale X and transform y before building model\n",
    "X_train_Scaled = scaler.transform(X_train)\n",
    "y_train_le = le.transform(y_train)\n",
    "# Reshape the X and y vectors\n",
    "X_almost_ready = np.asarray(X_train_Scaled).reshape(len(X_train_Scaled),549).astype(np.float)\n",
    "y_ready = np.asarray(y_train_le).reshape(len(y_train_le),1)\n",
    "# Apply the PCA transformer\n",
    "X_ready = q3pca.transform(X_almost_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76068376068376065"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\\\n",
    "                    X_ready, y_ready, test_size=0.2, random_state=0)\n",
    "\n",
    "# Build the model\n",
    "q3Model = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\n",
    "q3Model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the grader\n",
    "#rec = np.asarray(record).reshape(1,549).astype(np.float)\n",
    "#rec_transformed = q3pca.transform(rec)\n",
    "#yPred = q3Model.predict(rec_transformed)\n",
    "#le.inverse_transform(yPred[0])\n",
    "dill.dump(q3Model, open('Model.dill', 'w'))\n",
    "dill.dump(q3pca, open('PCA.dill', 'w'))\n",
    "dill.dump(le, open('Labels.dill', 'w'))\n",
    "dill.dump(scaler, open('Scaler.dill','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### other attempted models for Q2\n",
    "# Function to create features\n",
    "def create_features():\n",
    "    x = []\n",
    "    mono, fs = librosa.load('datasets/processed/mp3File.mp3', sr = 44100)\n",
    "    frameLength = int(len(mono)/20)\n",
    "    zcr = librosa.feature.zero_crossing_rate(mono, frame_length=2048, hop_length=512, center=True)\n",
    "    rms = librosa.feature.rmse(mono, S=None, n_fft=2048, hop_length=512)\n",
    "    mfcc= librosa.feature.mfcc(mono, sr=44100, S=None, n_mfcc=20)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=mono, sr=44100)\n",
    "    chroma = librosa.feature.chroma_stft(mono, sr=44100, S=None, norm=np.inf, n_fft=2048, hop_length=512, tuning=None)\n",
    "    mel_spec = librosa.feature.melspectrogram(mono, sr=44100, S=None, n_fft=2048, hop_length=512)\n",
    "    spec_cent = librosa.feature.spectral_centroid(mono, sr=44100, S=None, n_fft=2048, hop_length=512, freq=None)\n",
    "    spec_band = librosa.feature.spectral_bandwidth(mono, sr=44100, S=None, n_fft=2048, hop_length=512, freq=None, centroid=None,\\\n",
    "                                                   norm=True, p=2)\n",
    "    spec_contr = librosa.feature.spectral_contrast(mono, sr=44100, S=None, n_fft=2048, hop_length=512, freq=None, fmin=200.0,\\\n",
    "                                                   n_bands=6, quantile=0.02, linear=False)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(mono, sr=44100, S=None, n_fft=2048, hop_length=512, freq=None, roll_percent=0.85)\n",
    "    tonnetz = librosa.feature.tonnetz(mono, sr=44100, chroma=None)\n",
    "    tempogram = librosa.feature.tempogram(mono, sr=44100, onset_envelope=None, hop_length=512, win_length=384, center=True,\\\n",
    "                                          window=None, norm=np.inf)\n",
    "#    print 'Number of ZCR columns:%s\\nNumber of RMS columns:%s' % (len(zcr[0]), len(rms[0])) \n",
    "#    zcr:  (1, 867)\n",
    "#    rms:  (1, 867)\n",
    "#    mfcc:  (20, 867)\n",
    "#    spec_bw:  (1, 867)\n",
    "#    chroma:  (12, 867)\n",
    "#    mel_spec:  (128, 867)\n",
    "#    spec_cent:  (1, 867)\n",
    "#    spec_band:  (1, 867)\n",
    "#    spec_contr:  (7, 867)\n",
    "#    spec_rolloff:  (1, 867)\n",
    "#    tonnetz:  (6, 867)\n",
    "#    tempogram:  (384, 867)\n",
    "    \n",
    "    rms_mean = np.mean(rms[0])\n",
    "    rms_std  = np.std(rms[0])\n",
    "    rms_skew = scipy.stats.skew(rms[0], axis=0, bias=True)\n",
    " \n",
    "    zcr_mean = np.mean(zcr[0])\n",
    "    zcr_std  = np.std(zcr[0])\n",
    "    zcr_skew = scipy.stats.skew(zcr[0], axis=0, bias=True)\n",
    "    \n",
    "    spec_cent_mean = np.mean(spec_cent[0])\n",
    "    spec_cent_std  = np.std(spec_cent[0])\n",
    "    spec_cent_skew = scipy.stats.skew(spec_cent[0], axis=0, bias=True)\n",
    "   \n",
    "    spec_band_mean = np.mean(spec_band[0])\n",
    "    spec_band_std  = np.std(spec_band[0])\n",
    "    spec_band_skew = scipy.stats.skew(spec_band[0], axis=0, bias=True)\n",
    "       \n",
    "    spec_rolloff_mean = np.mean(spec_rolloff[0])\n",
    "    spec_rolloff_std  = np.std(spec_rolloff[0])\n",
    "    spec_rolloff_skew = scipy.stats.skew(spec_rolloff[0], axis=0, bias=True)\n",
    "       \n",
    "    spec_bw_mean = np.mean(spec_bw[0])\n",
    "    spec_bw_std  = np.std(spec_bw[0])\n",
    "    spec_bw_skew = scipy.stats.skew(spec_bw[0], axis=0, bias=True)\n",
    "       \n",
    "    mfcc_mean = []\n",
    "    mfcc_std  = []\n",
    "    mfcc_skew = []\n",
    "    mfcc_kurt = []\n",
    "    for i in range(len(mfcc[:, 0])):\n",
    "        mfcc_mean.append(np.mean(mfcc[i]))\n",
    "        mfcc_std.append(np.std(mfcc[i]))\n",
    "        mfcc_skew.append(scipy.stats.skew(mfcc[i], axis=0, bias=True))\n",
    "        mfcc_kurt.append(scipy.stats.kurtosis(mfcc[i], axis=0, fisher=True, bias=True))\n",
    "        \n",
    "    \n",
    "    chroma_mean = []\n",
    "    chroma_std  = []\n",
    "    chroma_skew = []\n",
    "    for i in range(len(chroma[:, 0])):\n",
    "        chroma_mean.append(np.mean(chroma[i,0]))\n",
    "        chroma_std.append(np.std(chroma[i]))\n",
    "        chroma_skew.append(scipy.stats.skew(chroma[i], axis=0, bias=True))\n",
    "        \n",
    "    mel_spec_mean = []\n",
    "    mel_spec_std  = []\n",
    "    mel_spec_skew = []\n",
    "    for i in range(len(mel_spec[:, 0])):\n",
    "        mel_spec_mean.append(np.mean(mel_spec[i]))\n",
    "        mel_spec_std.append(np.std(mel_spec[i]))\n",
    "        mel_spec_skew.append(scipy.stats.skew(mel_spec[i], axis=0, bias=True))\n",
    "        \n",
    "    spec_contr_mean = []\n",
    "    spec_contr_std  = []\n",
    "    spec_contr_skew = []\n",
    "    for i in range(len(spec_contr[:, 0])):\n",
    "        spec_contr_mean.append(np.mean(spec_contr[i]))\n",
    "        spec_contr_std.append(np.std(spec_contr[i]))\n",
    "        spec_contr_skew.append(scipy.stats.skew(spec_contr[i], axis=0, bias=True))\n",
    "        \n",
    "    tonnetz_mean = []\n",
    "    tonnetz_std  = []\n",
    "    tonnetz_skew = []\n",
    "    for i in range(len(tonnetz[:, 0])):\n",
    "        tonnetz_mean.append(np.mean(tonnetz[i]))\n",
    "        tonnetz_std.append(np.std(tonnetz[i]))\n",
    "        tonnetz_skew.append(scipy.stats.skew(tonnetz[i], axis=0, bias=True))\n",
    "        \n",
    "    tempogram_mean = []\n",
    "    tempogram_std  = []\n",
    "    tempogram_skew = []\n",
    "    for i in range(len(tempogram[:, 0])):\n",
    "        tempogram_mean.append(np.mean(tempogram[i]))                \n",
    "        tempogram_std.append(np.std(tempogram[i]))\n",
    "        tempogram_skew.append(scipy.stats.skew(tempogram[i], axis=0, bias=True))\n",
    "        \n",
    "    x = [[rms_mean, rms_std, rms_skew, zcr_mean, zcr_std, zcr_skew, spec_bw_mean, spec_bw_std, spec_bw_skew],\\\n",
    "         [spec_cent_mean, spec_cent_std, spec_cent_skew, spec_band_mean, spec_band_std, spec_band_skew],\\\n",
    "         [spec_rolloff_mean, spec_rolloff_std, spec_rolloff_skew],\\\n",
    "         mfcc_mean, mfcc_std, mfcc_skew, chroma_mean, chroma_std, chroma_skew, mel_spec_mean, mel_spec_std, mel_spec_skew,\\\n",
    "         spec_contr_mean, spec_contr_std, spec_contr_skew, tonnetz_mean, tonnetz_std, tonnetz_skew,\\\n",
    "         tempogram_mean, tempogram_std, tempogram_skew ]\n",
    "    \n",
    "    X = [item for sublist in x for item in sublist]\n",
    "    \n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
